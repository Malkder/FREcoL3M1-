### Notions de convergence de variables aléatoires

#### **La convergence de variable aléatoires**
- Utilisation de règles de convergence spécifique pour des variables aléatoires...
- Comportement à la limite d'une séquence de variables aléatoires : $(Z_{1},Z_{2},\dots,Z_{N}) \implies {Z_{N}}$
- Quand $N \rightarrow \infty$, est-ce que cette séquence converge ?
	Vers une valeur fixe ? $\rightarrow$ convergence
	Vers une variable aléatoire ? $\rightarrow$ convergence
	Vers une distribution connue ? $\rightarrow$ théorèmes central-limite

##### **Définition 1: Convergence en probabilit**é
> Une séquence de variables aléatoires $\{Z_N\}$ converge en probabilité vers une constante (non-aléatoire) $\alpha$ si, pour tout $\epsilon > 0$ : $$\begin{align*} \lim_{N \to \infty} \Pr(|Z_N - \alpha| > \epsilon) &= 0 \end{align*}$$
La définition stipule qu'une séquence de variables aléatoires $\{Z_N\}$ converge en probabilité vers une constante (non-aléatoire) $\alpha$ si, pour tout $\epsilon > 0$, la probabilité que la valeur de $Z_N$ soit supérieure à $\alpha + \epsilon$ tend vers 0 lorsque le nombre de termes de la séquence, $n$, tend vers l'infini.

- La constante $a$ est appelée la limite en probabilité de $Z_n$.
- On note : $Z_N \overset{p}\to \alpha$ ou $\text{p}\lim Z_n = \alpha$ =>  $\text{p}\lim Z_n = \alpha$ indique que $Z_n$ converge en probabilité vers $\alpha$.
	La définition est généralisée à un vecteur ou une matrice de variables aléatoires en stipulant que chacun de leurs éléments converge en probabilité vers une constante propre.

###### **Définition 2: Convergence presque sûre**
>Une séquence de variables aléatoires $\{Z_n\}$ converge presque sûrement vers une constante (non-aléatoire) $\alpha$ si :
$\Pr(\lim_{N \to \infty} Z_N = \alpha) = 1$
La définition stipule qu'une séquence de variables aléatoires $\{Z_N\}$ converge presque sûrement vers une constante (non-aléatoire) $\alpha$ si, pour tout événement $\mathrm{A}$ tel que la probabilité que $\mathrm{A}$ se produise soit nulle, la probabilité que $Z_N$ appartienne à $\mathrm{A}$ pour un nombre infini de valeurs de $N$ est également nulle.
En d'autres termes, la convergence presque sûre signifie que la valeur de $Z_N$ est égale à $\alpha$ pour presque tous les $N$
- La constante $\alpha$ est appelée la limite presque sûre de $Z_n$.
	On note :
	$Z_N \overset{a.s}\to \alpha$
- La convergence presque sûre est souvent utilisée pour montrer que les estimations sont convergentes.
- La convergence presque sûre est une notion de convergence plus "forte" que la convergence en probabilité si : $Z_N \overset{a.s}\to \alpha \implies Z_N \overset{p}\to \alpha$
- Le corollaire n'est pas toujours vrai*
> Exemple :
> Soit $Z_n = \frac{1}{n}$. La suite $\{Z_n\}$ converge en probabilité vers 0. Cependant, la suite $\{Z_n\}$ ne converge pas presque sûrement vers 0, car la probabilité que $Z_n = 1$ est non nulle pour tout $n$.

##### **Définition 3: Convergence en moyenne quadratique**
>Une suite de variables aléatoires $\{Z_{N​}\}$ converge en moyenne quadratique vers une constante (non-aléatoire) $\alpha$ si :
$\lim_{N \to \infty} \mathbb{E}[Z_{N}]=\alpha$ et $\lim_{N \to \infty} \mathbb{E}[(Z_N - \alpha)^2] = 0$
La définition stipule qu'une suite de variables aléatoires $\{Z_{N​}\}$ converge en moyenne quadratique vers une constante (non aléatoire) $\alpha$ si, pour tout $\epsilon > 0$, la variance de $Z_N - \alpha$ tend vers 0 lorsque le nombre de termes de la suite, $N$, tend vers l'infini.

- La constante $\alpha$ est appelée la limite en moyenne quadratique de $Z_n$.
	On note :
	$Z_N \overset{m.s}\to \alpha$
- Ainsi, si : $\lim_{N \to \infty} \mathbb{E}[Z_{N}]=\alpha$ et $\lim_{N \to \infty} \mathbb{V}[(Z_N)] = 0$, alors $Z_N \overset{m.s}\to \alpha$	
- La convergence en moyenne quadratique est une notion de convergence plus "forte" que la convergence en probabilité si : $Z_N \overset{m.s}\to \alpha \implies Z_N \overset{p}\to \alpha$
- Le corollaire n'est pas toujours vrai*
>**Note importante (rajout personnel)**
La notation $\lim_{N \to \infty} \mathbb{V}[(Z_N)] = 0$ est équivalente à la notation $\lim_{N \to \infty} \mathbb{E}[(Z_N - \alpha)^2] = 0$. 
Pour être précis ; $\lim_{N \to \infty} \mathbb{E}[(Z_N - \alpha)^2] = 0 \implies \lim_{N \to \infty} \mathbb{V}[(Z_N)] = 0$ car
$\text{Var}(Z_N - \alpha) = \mathbb{E}[(Z_N - \alpha - \mu)^2]$
$\equiv \text{Var}(Z_N - \alpha) = \mathbb{E}[Z_N^2 - 2Z_N \alpha + \alpha^2]$
$\equiv \text{Var}(Z_N - \alpha) = \mathbb{E}[Z_N^2] - 2 \alpha \mathbb{E}[Z_N] + \alpha^2$
$\equiv \lim_{N \to \infty} \mathbb{E}[Z_N^2] - 2 \alpha \mathbb{E}[Z_N] + \alpha^2 = 0$
En effet, si la variance de la suite est égale à 0, alors la moyenne des carrés des écarts à la moyenne est égale à 0. Par conséquent, les notations sont équivalentes

##### **Définition 4: Convergence en probabilité vers une variable aléatoire**
> Une séquence de variables aléatoires $\{Z_N\}$ converge en probabilité vers une variable aléatoire $Z$ si :
> $Z_{N}-Z\overset{p}\to 0$ alors $Z_{N}\overset{p}\to Z$
> (ou $\lim_{N \to \infty} \mathbb{P}(Z_N \in \mathcal{A}) = \mathbb{P}(Z \in \mathcal{A})$)
> La définition stipule qu'une suite de variables aléatoires $\{Z_{N}\}$ converge en probabilité vers une variable aléatoire $Z$ si, pour tout événement $\mathcal{A}$ tel que la probabilité que $Z$appartienne à $\mathcal{A}$ soit non nulle, la probabilité que $\{Z_{N}\}$​ appartienne à $\mathcal{A}$ tend vers la probabilité que $Z$ appartienne à $\mathcal{A}$ lorsque le nombre de termes de la suite, $N$, tend vers l'infini.

- Ainsi :
	$Z_N - Z \overset{a.s}\to 0$ alors $Z_N \overset{a.s}\to Z$
	$Z_N - Z \overset{m.s}\to 0$ alors $Z_N \overset{m.s}\to Z$
- La convergence en probabilité vers une variable aléatoire implique une convergence en probabilité vers une constante : $\lim_{n \to \infty} \mathbb{P}(Z_n = c) = \mathbb{P}(Z = c)$
- La convergence en probabilité est une notion de convergence plus "forte" que la convergence en distribution si : $Z_N \overset{p}\to Z \implies Z_N \overset{d}\to Z$ 

##### **Définition 5: Convergence en distribution**
> Soit une suite de variables aléatoires $\{Z_n\}$ avec une fonction de distribution $F_N(Z_{N})$, on dira que $\{Z_N\}$ converge en distribution vers une variable aléatoire $Z$ si la limite de la fonction de distribution de $Z_n$ est égale à la fonction de distribution de $Z$ : $\lim_{n \to \infty} F_n(z) = F(z)$.

- On note :
	$Z_N \overset{d}\to Z$ ou $Z_N \overset{L}\to Z$ ou $Z_N \overset{d}\to F$
 - La convergence en distribution implique une convergence en probabilité si la séquence converge vers une constante, on note alors : $Z_N \overset{p}\to \alpha \implies Z_N \overset{d}\to \alpha$

##### **Définition 6 : Distribution asymptotique**
> $F$ est appelé la distribution asymptotique ou la distribution limite de $Z_{N}$

Se référer définition 5

##### **Lemme 2.3. : Préservation de la convergence avec une transformation continue**
>Soit $\{Z_N​\}$ une suite de variables aléatoires convergeant en distribution vers une variable aléatoire $Z$. Soit $g$ une fonction continue. Alors, la suite ${g(Z_{N})}$ (ne dépendant pas de N) converge en distribution vers la variable aléatoire $g(Z)$.
>Si $Z_{N}\overset{p}\to a \implies g(Z_n) \overset{p}\to g(a)$ ou si $p\lim g (Z_{N})=g(p\lim Z_{N})$
Si : $Z_{N}\overset{d}\to Z \implies g(Z_n) \overset{d}\to g(Z)$

Conséquences du Lemme :
- $X_{N}\overset{P}\to \beta \text{ et } Y_{N}\overset{P}\to \alpha \implies X_{N}+Y_{N}\overset{P} \to \beta+\alpha$
- 





