#### Linéarité du modèle
Soit $\mathbf{x_i}$ le vecteur colonne de n observation de la variable $x_k$ avec $k=1,...,K$ et $\mathbf{X}$ une matricen $n\times K$ constituée de données ainsi empiliées.
Soit $\mathbf{y}$ les $n$ observations, $y_1,...,y_n$ et soit $\mathbf{\epsilon}$ le vecteur colonne de $n$ perturbation
Alors ; $$\mathbf{y}=\mathbf{x}_1 \beta_1 + ... + \mathbf{x}_k \beta_k + \mathbf{\epsilon} \equiv \mathbf{X \beta} + \mathbf{\epsilon}$$
#### Hypothèse de plein rang
Il n'existe pas de relation linéaire entre les variables. Les colonnes de $\mathbf{X}$ sont linéairement indépendantes et il y a au moins $K$ observations.
Ainsi ; $\mathbf{X}$ est une matrice $n\times K$ de rang $K$ 

#### Exogénéité des variables indépendantes
La structure du terme de l'erreur est telle que :
$$E[\epsilon_i \vert \mathbf{X}]=0$$ Ainsi ; $$E[\epsilon_i \vert \mathbf{X}]= \begin{pmatrix} E[\epsilon_1 \vert \mathbf{X}] \\ E[\epsilon_2 \vert \mathbf{X}] \\  \vdots \\E[\epsilon_n \vert \mathbf{X}]\end{pmatrix} = 0$$
Ce qui se traduit par aucune observations sur $\mathbf{x}$ ne porte d'information sur l'espérance de la perturbations.
Elle implique par ailleurs que :
- $E[\epsilon_i]=0$ car $E_\mathbf{x}[\epsilon_i \vert \mathbf{X}]=E_\mathbf{x}[0]=0$
- $E[\mathbf{y \vert X}] = \mathbf{X}\beta$ 

#### L'homoscédasticité et absence d'autocorrélation

Var$[\epsilon_i \vert \mathbf{X}] = \sigma^2$ -> Variance constante donc homoscédasticité
cov$[\epsilon_i, \epsilon_j \vert \mathbf{X}]=0$ 
Ainsi ; 
E$[\epsilon\epsilon' \vert \mathbf{X} = \sigma^2 \mathbf{I}$]

#### Distribution normale
Les perturbations sont normalement distribué : 
$\epsilon \vert \mathbf{X} \sim N[\mathbf{0}, \sigma^2 \mathbf{I}$]
